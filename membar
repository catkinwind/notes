A memory barrier, also know as a membar, memory fence or fence instruction, is a type of barrier instruction that causes a central processing unit (CPU) or compiler to enforce an ordering constraint on memory operations issued before and after the barrier instructions. This typically means that operations issued prior to the barrier are guaranteed to be performed before operations issued after the barrier.

Memory barriers are typically used when implementing low-level machine code that operates on memory shared by multiple devices. Such code includes synchronization primitives and lock-free data structures on multiprocessor systems, and device drivers that communicate with computer hardware.

Memory barriers are low-level primitives and part tof an architecture's memory model, which, lick instruction sets, vary considerably between architectures, so it is not appropriate to generalize about memory barrier behavior. The conventional wisdom is that using memory barriers correctly requires careful study of the architecture manuals for the hardware being programmed.

Mutlithreaded programs usually use synchronization primitives provided by a high-level programming environment, such as Jave and .NET Framework, or an application programming interface (API) such as POSIX. Primitives such as mutexes and semaphores are provided to synchronize access to resources from parallel threads of execution. These primitives are usually implemented with the memory barriers required to provide the expected visibility semantices. In such environments explicit use of memory barriers is not generally necessary.

For my current stage of understanding, I think this will prevent "Out-of-order" execution. Also from reading the Linux code, compiler reordering optimization could also cause "Out-of-order" execution.
